{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71c23d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "CSV_PATH = \"NeoJaundice/chd_jaundice_published_2.csv\"\n",
    "IMG_DIR = \"NeoJaundice/images\"\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "images, labels = [], []\n",
    "\n",
    "# Load and central crop\n",
    "def crop_center(img, fraction=0.4):\n",
    "    h, w = img.shape[:2]\n",
    "    ch, cw = int(h * fraction), int(w * fraction)\n",
    "    start_x, start_y = (w - cw) // 2, (h - ch) // 2\n",
    "    return img[start_y:start_y+ch, start_x:start_x+cw]\n",
    "def white_balance_with_yellow_patch(img, top_left=(90, 330), size=20):\n",
    "    y, x = top_left\n",
    "    patch = img[y:y+size, x:x+size]\n",
    "    avg = np.mean(patch.reshape(-1, 3), axis=0)\n",
    "    gain = np.array([0, 255, 255], dtype=np.float32) / (avg + 1e-6)\n",
    "    balanced = np.clip(img.astype(np.float32) * gain, 0, 255).astype(np.uint8)\n",
    "    return balanced\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    path = os.path.join(IMG_DIR, row['image_idx'])\n",
    "    if os.path.exists(path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(crop_center(img), (128, 128))\n",
    "        images.append(img)\n",
    "        labels.append(row['blood(mg/dL)'])\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77562298",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, hsv = [], []\n",
    "\n",
    "for img in images:\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) / 255.0\n",
    "\n",
    "    rgb_flat = rgb_img.reshape(-1, 3).T[:, :1223]  # (3, 1223)\n",
    "    hsv_flat = hsv_img.reshape(-1, 3).T[:, :1223]  # (3, 1223)\n",
    "\n",
    "    rgb.append(rgb_flat)\n",
    "    hsv.append(hsv_flat)\n",
    "\n",
    "rgb = np.array(rgb)  # (N, 3, 1223)\n",
    "hsv = np.array(hsv)  # (N, 3, 1223)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff2eeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_rgb_train, X_rgb_test, X_hsv_train, X_hsv_test, y_train, y_test = train_test_split(\n",
    "    rgb, hsv, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0a35c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(X):\n",
    "    N, C, T = X.shape\n",
    "    X_flat = X.reshape(N, -1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_flat).reshape(N, C, T)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "# Apply to both branches\n",
    "X_rgb_train, rgb_scaler = standardize(X_rgb_train)\n",
    "X_hsv_train, hsv_scaler = standardize(X_hsv_train)\n",
    "\n",
    "X_rgb_test = rgb_scaler.transform(X_rgb_test.reshape(X_rgb_test.shape[0], -1)).reshape(-1, 3, 1223)\n",
    "X_hsv_test = hsv_scaler.transform(X_hsv_test.reshape(X_hsv_test.shape[0], -1)).reshape(-1, 3, 1223)\n",
    "# Swap axes\n",
    "X_rgb_train = np.transpose(X_rgb_train, (0, 2, 1))  # (N, 1223, 3)\n",
    "X_hsv_train = np.transpose(X_hsv_train, (0, 2, 1))\n",
    "X_rgb_test = np.transpose(X_rgb_test, (0, 2, 1))\n",
    "X_hsv_test = np.transpose(X_hsv_test, (0, 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6cff771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_rgb_train, X_hsv_train], axis=-1)\n",
    "X_test  = np.concatenate([X_rgb_test, X_hsv_test], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "75e6dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 1223, 6)]         0         \n",
      "                                                                 \n",
      " conv1d_128 (Conv1D)         (None, 1223, 32)          608       \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 1223, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_124 (MaxPool  (None, 612, 32)           0         \n",
      " ing1D)                                                          \n",
      "                                                                 \n",
      " conv1d_129 (Conv1D)         (None, 612, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 612, 64)           256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_125 (MaxPool  (None, 306, 64)           0         \n",
      " ing1D)                                                          \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 306, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 306, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_126 (MaxPool  (None, 153, 128)          0         \n",
      " ing1D)                                                          \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 153, 128)          49280     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 153, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_127 (MaxPool  (None, 77, 128)           0         \n",
      " ing1D)                                                          \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 9856)              0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 256)               2523392   \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2638625 (10.07 MB)\n",
      "Trainable params: 2637921 (10.06 MB)\n",
      "Non-trainable params: 704 (2.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define single-branch model\n",
    "input_layer = Input(shape=(1223, 6))  # Combined RGB+HSV\n",
    "\n",
    "x = Conv1D(32, 3, activation='relu', padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='linear')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=5e-4), loss='mse', metrics=['mae'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ee5e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "45/45 [==============================] - 6s 110ms/step - loss: 42.8057 - mae: 5.1148 - val_loss: 97.8490 - val_mae: 8.5892 - lr: 5.0000e-04\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 32.0928 - mae: 4.4954 - val_loss: 57.1456 - val_mae: 6.3661 - lr: 5.0000e-04\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 27.2449 - mae: 4.1794 - val_loss: 37.5922 - val_mae: 5.0523 - lr: 5.0000e-04\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - 4s 91ms/step - loss: 25.5491 - mae: 4.0445 - val_loss: 30.8961 - val_mae: 4.4554 - lr: 5.0000e-04\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - 4s 85ms/step - loss: 24.5408 - mae: 3.9019 - val_loss: 30.7018 - val_mae: 4.4122 - lr: 5.0000e-04\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - 4s 84ms/step - loss: 21.5666 - mae: 3.6454 - val_loss: 29.1792 - val_mae: 4.2914 - lr: 5.0000e-04\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - 4s 85ms/step - loss: 22.4003 - mae: 3.7810 - val_loss: 25.8789 - val_mae: 3.9781 - lr: 5.0000e-04\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - 4s 91ms/step - loss: 21.9283 - mae: 3.6760 - val_loss: 24.5277 - val_mae: 3.9019 - lr: 5.0000e-04\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - 4s 85ms/step - loss: 19.6707 - mae: 3.5167 - val_loss: 19.4355 - val_mae: 3.3641 - lr: 5.0000e-04\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - 4s 99ms/step - loss: 18.6749 - mae: 3.4492 - val_loss: 19.6397 - val_mae: 3.3878 - lr: 5.0000e-04\n",
      "Epoch 11/150\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 18.8352 - mae: 3.4398 - val_loss: 22.6846 - val_mae: 3.6461 - lr: 5.0000e-04\n",
      "Epoch 12/150\n",
      "45/45 [==============================] - 5s 103ms/step - loss: 17.3325 - mae: 3.3145 - val_loss: 17.7704 - val_mae: 3.2764 - lr: 5.0000e-04\n",
      "Epoch 13/150\n",
      "45/45 [==============================] - 4s 92ms/step - loss: 16.9130 - mae: 3.2571 - val_loss: 19.3896 - val_mae: 3.4042 - lr: 5.0000e-04\n",
      "Epoch 14/150\n",
      "45/45 [==============================] - 4s 94ms/step - loss: 17.4031 - mae: 3.2804 - val_loss: 17.0781 - val_mae: 3.1262 - lr: 5.0000e-04\n",
      "Epoch 15/150\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 17.0344 - mae: 3.2970 - val_loss: 19.1033 - val_mae: 3.2734 - lr: 5.0000e-04\n",
      "Epoch 16/150\n",
      "45/45 [==============================] - 5s 104ms/step - loss: 16.3231 - mae: 3.1755 - val_loss: 19.5899 - val_mae: 3.4380 - lr: 5.0000e-04\n",
      "Epoch 17/150\n",
      "45/45 [==============================] - 4s 90ms/step - loss: 16.1414 - mae: 3.2131 - val_loss: 19.7662 - val_mae: 3.4208 - lr: 5.0000e-04\n",
      "Epoch 18/150\n",
      "45/45 [==============================] - 4s 91ms/step - loss: 15.4683 - mae: 3.1182 - val_loss: 17.4792 - val_mae: 3.2271 - lr: 5.0000e-04\n",
      "Epoch 19/150\n",
      "45/45 [==============================] - 4s 95ms/step - loss: 15.1755 - mae: 3.0841 - val_loss: 18.7984 - val_mae: 3.2488 - lr: 5.0000e-04\n",
      "Epoch 20/150\n",
      "45/45 [==============================] - 4s 96ms/step - loss: 14.2846 - mae: 2.9773 - val_loss: 16.9966 - val_mae: 3.1170 - lr: 5.0000e-04\n",
      "Epoch 21/150\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 13.9532 - mae: 2.9347 - val_loss: 18.1115 - val_mae: 3.2236 - lr: 5.0000e-04\n",
      "Epoch 22/150\n",
      "45/45 [==============================] - 4s 86ms/step - loss: 13.3975 - mae: 2.8254 - val_loss: 22.9537 - val_mae: 3.7426 - lr: 5.0000e-04\n",
      "Epoch 23/150\n",
      "45/45 [==============================] - 4s 97ms/step - loss: 13.4928 - mae: 2.8758 - val_loss: 17.6877 - val_mae: 3.1931 - lr: 5.0000e-04\n",
      "Epoch 24/150\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 13.3220 - mae: 2.9008 - val_loss: 17.9262 - val_mae: 3.2142 - lr: 5.0000e-04\n",
      "Epoch 25/150\n",
      "45/45 [==============================] - 4s 96ms/step - loss: 11.9707 - mae: 2.7256 - val_loss: 19.9265 - val_mae: 3.4460 - lr: 5.0000e-04\n",
      "Epoch 26/150\n",
      "45/45 [==============================] - 4s 85ms/step - loss: 11.7360 - mae: 2.6877 - val_loss: 20.9088 - val_mae: 3.4469 - lr: 5.0000e-04\n",
      "Epoch 27/150\n",
      "45/45 [==============================] - 4s 96ms/step - loss: 12.3778 - mae: 2.7683 - val_loss: 18.9861 - val_mae: 3.3529 - lr: 5.0000e-04\n",
      "Epoch 28/150\n",
      "45/45 [==============================] - 4s 86ms/step - loss: 11.2075 - mae: 2.6333 - val_loss: 17.6020 - val_mae: 3.2588 - lr: 5.0000e-04\n",
      "Epoch 29/150\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 11.8731 - mae: 2.6903 - val_loss: 20.4217 - val_mae: 3.3935 - lr: 5.0000e-04\n",
      "Epoch 30/150\n",
      "45/45 [==============================] - 5s 102ms/step - loss: 11.6060 - mae: 2.6703 - val_loss: 17.8502 - val_mae: 3.1691 - lr: 5.0000e-04\n",
      "Epoch 31/150\n",
      "45/45 [==============================] - 4s 99ms/step - loss: 11.0282 - mae: 2.5799 - val_loss: 18.7293 - val_mae: 3.2753 - lr: 2.5000e-04\n",
      "Epoch 32/150\n",
      "45/45 [==============================] - 4s 90ms/step - loss: 9.6387 - mae: 2.4319 - val_loss: 18.6642 - val_mae: 3.2253 - lr: 2.5000e-04\n",
      "Epoch 33/150\n",
      "45/45 [==============================] - 4s 99ms/step - loss: 9.6175 - mae: 2.4071 - val_loss: 17.8675 - val_mae: 3.1588 - lr: 2.5000e-04\n",
      "Epoch 34/150\n",
      "45/45 [==============================] - 4s 84ms/step - loss: 8.7149 - mae: 2.2805 - val_loss: 18.6823 - val_mae: 3.2450 - lr: 2.5000e-04\n",
      "Epoch 35/150\n",
      "45/45 [==============================] - 4s 85ms/step - loss: 8.7639 - mae: 2.3186 - val_loss: 18.0207 - val_mae: 3.1891 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27bcecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 13ms/step\n",
      "\n",
      "Final Results\n",
      "RMSE: 4.01\n",
      "MAE: 3.05\n",
      "R²: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "preds = model.predict([X_test])\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nFinal Results\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nR²: {r2:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
